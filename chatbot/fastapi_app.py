"""
FastAPI æœå‹™ - RAG èŠå¤©æ©Ÿå™¨äºº (å¤šå­¸ç§‘æ”¯æ´ç‰ˆ)
ç”¨æ–¼å­¸ç”Ÿå•ç­”ç³»çµ±çš„å¾Œç«¯ API
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import os
import sys
import time
from dotenv import load_dotenv

# è¨­å®šè·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)

if project_root not in sys.path:
    sys.path.append(project_root)

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
env_path = os.path.join(project_root, ".env")
load_dotenv(env_path)

# å°å…¥ RAG ç›¸é—œæ¨¡çµ„
from chatbot.rag_pipeline.RAG_function import rag_process


def get_drawing_info(retrieved_docs):
    import json

    DRAWING_DIR = os.path.join(
        project_root, "chatbot", "dataset", "llama_drawing_steps"
    )

    for doc in retrieved_docs:
        if hasattr(doc, "metadata"):
            doc_id = doc.metadata.get("id")
            if doc_id:
                target_filename = f"{doc_id}_layout.json"
                full_path = os.path.join(DRAWING_DIR, target_filename)

                if os.path.exists(full_path):
                    try:
                        with open(full_path, "r", encoding="utf-8") as f:
                            data = json.load(f)
                            steps = len(data.get("steps", []))
                            return str(doc_id), steps
                    except Exception as e:
                        print(f"è®€å– Layout JSON å¤±æ•—: {e}")
                        continue
    return None, 0


# ==================== Pydantic Models ====================


class ChatMessage(BaseModel):
    role: str = Field(..., description="user æˆ– assistant")
    content: str = Field(..., description="è¨Šæ¯å…§å®¹")


class ChatRequest(BaseModel):
    """èŠå¤©è«‹æ±‚æ¨¡å‹"""

    message: str = Field(..., description="å­¸ç”Ÿçš„å•é¡Œ", min_length=1)
    subject: str = Field(
        default="math", description="ç§‘ç›®: math (æ•¸å­¸) æˆ– science (è‡ªç„¶)"
    )
    search_type: str = Field(
        default="teaching", description="æª¢ç´¢é¡å‹: teaching, exercise, hybrid"
    )
    learner_style: str = Field(
        default="æ¨™æº–ç´š", description="å­¸ç¿’é¢¨æ ¼: åŸºç¤ç´š, æ¨™æº–ç´š, é€²éšç´š"
    )
    course_id: Optional[int] = Field(default=None, description="èª²ç¨‹ IDï¼ˆå¯é¸ï¼‰")
    course_title: Optional[str] = Field(default=None, description="èª²ç¨‹æ¨™é¡Œ/ä¸»é¡Œ")
    history: Optional[List[ChatMessage]] = Field(default=[], description="å°è©±æ­·å²")
    is_retry: bool = Field(default=False, description="æ˜¯å¦ç‚ºé‡è©¦è«‹æ±‚")
    retry_count: int = Field(default=0, description="é‡è©¦æ¬¡æ•¸")
    use_alternative: bool = Field(default=False, description="æ˜¯å¦ä½¿ç”¨æ›¿ä»£è§£é‡‹")


class ChatResponse(BaseModel):
    answer: str = Field(..., description="AI ç”Ÿæˆçš„ç­”æ¡ˆ")
    segments: List[str] = Field(default=[], description="ç­”æ¡ˆåˆ†æ®µ")
    retrieved_docs: List[Dict[str, Any]] = Field(
        default=[], description="æª¢ç´¢åˆ°çš„ç›¸é—œæ–‡ä»¶"
    )
    processing_time: float = Field(..., description="è™•ç†æ™‚é–“")
    search_type: str = Field(..., description="ä½¿ç”¨çš„æª¢ç´¢é¡å‹")
    learner_style: str = Field(..., description="ä½¿ç”¨çš„å­¸ç¿’é¢¨æ ¼")
    exercise_question: Optional[str] = Field(default=None)
    exercise_answer: Optional[str] = Field(default=None)
    drawing_id: Optional[str] = Field(default=None)
    drawing_total_steps: int = Field(default=0)


class ClarifyRequest(BaseModel):
    selected_text: str = Field(..., description="å­¸ç”Ÿé¸ä¸­çš„æ–‡å­—ç‰‡æ®µ")
    original_query: str = Field(..., description="åŸå§‹å•é¡Œ")
    learner_style: str = Field(default="æ¨™æº–ç´š")
    original_context: Optional[str] = Field(default=None)


class ClarifyResponse(BaseModel):
    clarification: str = Field(..., description="æ·±å…¥è§£é‡‹")
    processing_time: float = Field(..., description="è™•ç†æ™‚é–“")


class HealthResponse(BaseModel):
    status: str
    rag_loaded: bool
    message: str


# ==================== FastAPI App ====================

app = FastAPI(
    title="RAG èŠå¤©æ©Ÿå™¨äºº API (å¤šå­¸ç§‘)",
    description="æ”¯æ´æ•¸å­¸èˆ‡è‡ªç„¶ç§‘çš„å•ç­”ç³»çµ±",
    version="2.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== å…¨åŸŸè®Šæ•¸ ====================

rag_service = None
rag_initialized = False

# ä½¿ç”¨å­—å…¸ä¾†ç®¡ç†ä¸åŒç§‘ç›®çš„ VectorStore
# çµæ§‹: { "math": {"teaching": VS, "exercise": VS}, "science": ... }
vector_stores = {
    "math": {"teaching": None, "exercise": None},
    "science": {"teaching": None, "exercise": None},
}

# è³‡æ–™è·¯å¾‘é…ç½® (éœ€èˆ‡ build_faiss.py å°æ‡‰)
PATH_CONFIG = {
    "math": {
        "teaching": "faiss_index_teaching",
        "exercise": "faiss_index_exercise",
        "ex_json": os.path.join(
            DATASET_DIR := os.path.join(current_dir, "dataset"),
            "raw_data",
            "add_id_data",
            "question_math_id.json",
        ),
    },
    "science": {
        "teaching": "faiss_index_science_teaching",
        "exercise": "faiss_index_science_exercise",
        "ex_json": os.path.join(
            DATASET_DIR, "raw_data", "add_id_data", "question_science_id.json"
        ),
    },
}

# ==================== å•Ÿå‹•äº‹ä»¶ ====================


@app.on_event("startup")
async def startup_event():
    global rag_service, rag_initialized, vector_stores
    print("\n" + "=" * 60)
    print("ğŸš€ FastAPI RAG æœå‹™å•Ÿå‹•ä¸­ (å¤šå­¸ç§‘æ¨¡å¼)...")
    print("=" * 60)

    try:
        # åˆå§‹åŒ– RAG è™•ç†å™¨
        print("\n[1/3] åˆå§‹åŒ– RAG è™•ç†å™¨...")
        rag_service = rag_process()

        # æº–å‚™ Embedding æ¨¡å‹
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import HuggingFaceBgeEmbeddings
        from chatbot.config import embedding_model_name, model_device

        model_kwargs = {"device": model_device}
        embeddings = HuggingFaceBgeEmbeddings(
            model_name=embedding_model_name,
            model_kwargs=model_kwargs,
            encode_kwargs={"normalize_embeddings": True},
        )
        print("   âœ… Embedding æ¨¡å‹è¼‰å…¥å®Œæˆ")

        # è¼‰å…¥æ‰€æœ‰ç§‘ç›®çš„å‘é‡åº«
        print("\n[2/3] è¼‰å…¥å‘é‡è³‡æ–™åº«...")

        for subj, paths in PATH_CONFIG.items():
            t_path = os.path.join(current_dir, paths["teaching"])
            e_path = os.path.join(current_dir, paths["exercise"])

            # è¼‰å…¥æ•™å­¸åº«
            if os.path.exists(t_path):
                print(f"   ğŸ“š [{subj}] è¼‰å…¥æ•™å­¸å‘é‡åº«: {paths['teaching']}")
                vector_stores[subj]["teaching"] = FAISS.load_local(
                    t_path, embeddings, allow_dangerous_deserialization=True
                )
            else:
                print(f"   âš ï¸ [{subj}] æ‰¾ä¸åˆ°æ•™å­¸åº«: {paths['teaching']}")

            # è¼‰å…¥ç·´ç¿’åº«
            if os.path.exists(e_path):
                print(f"   ğŸ“š [{subj}] è¼‰å…¥ç·´ç¿’å‘é‡åº«: {paths['exercise']}")
                vector_stores[subj]["exercise"] = FAISS.load_local(
                    e_path, embeddings, allow_dangerous_deserialization=True
                )
            else:
                print(f"   âš ï¸ [{subj}] æ‰¾ä¸åˆ°ç·´ç¿’åº«: {paths['exercise']}")

        # æª¢æŸ¥ OpenAI API Key
        print("\n[3/3] æª¢æŸ¥ OpenAI API...")
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("æ‰¾ä¸åˆ° OPENAI_API_KEY")

        rag_initialized = True
        print("\nâœ… æœå‹™å•Ÿå‹•æˆåŠŸï¼")

    except Exception as e:
        print(f"\nâŒ å•Ÿå‹•å¤±æ•—: {str(e)}")
        rag_initialized = False
        raise


@app.get("/health", response_model=HealthResponse)
async def health_check():
    return HealthResponse(
        status="ok" if rag_initialized else "error",
        rag_loaded=rag_initialized,
        message="RAG æœå‹™é‹è¡Œæ­£å¸¸" if rag_initialized else "RAG æœå‹™æœªåˆå§‹åŒ–",
    )


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    if not rag_initialized:
        raise HTTPException(status_code=503, detail="RAG æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")

    start_time = time.time()

    try:
        # 1. æ±ºå®šç§‘ç›® (é˜²å‘†)
        current_subject = (
            request.subject if request.subject in ["math", "science"] else "math"
        )

        # 2. å–å‡ºå°æ‡‰çš„ VectorStore
        selected_vs = vector_stores[current_subject]
        if not selected_vs["teaching"] or not selected_vs["exercise"]:
            # å¦‚æœè©²ç§‘ç›®çš„è³‡æ–™åº«æ²’è¼‰å…¥ï¼Œå›é€€åˆ° math æˆ–å ±éŒ¯
            if current_subject == "science" and vector_stores["math"]["teaching"]:
                print("Warning: Science DB not found, fallback to Math")
                selected_vs = vector_stores["math"]
                current_subject = "math"
            else:
                raise HTTPException(
                    status_code=400, detail=f"ç§‘ç›® {current_subject} çš„è³‡æ–™åº«æœªè¼‰å…¥"
                )

        # æ§‹å»º DB Tuple (VS, DS) - é€™è£¡ç°¡åŒ– DS ç‚ºç©ºåˆ—è¡¨
        teaching_db = (selected_vs["teaching"], [])
        exercise_db = (selected_vs["exercise"], [])

        # é©—è­‰åƒæ•¸
        if request.search_type == "teaching":
            top_n = 3
        elif request.search_type == "exercise":
            top_n = 1
        else:
            top_n = 4

        # 3. æª¢ç´¢
        retrieved = rag_service.retrival_step(
            [request.message],
            request.search_type,
            teaching_db,
            exercise_db,
            top_n=top_n,
            course_filter=request.course_title,
        )

        retrieved_docs = retrieved.get(request.message, [])

        # åœ–ç‰‡é‚è¼¯ (ç°¡åŒ–ç‰ˆï¼šåªåœ¨ math æˆ– science çš„ç‰¹å®šæƒ…æ³ä¸‹æ‰¾)
        drawing_id, total_steps = get_drawing_info(retrieved_docs)

        # 4. ç”Ÿæˆç­”æ¡ˆ
        matched_context = "\n".join(
            [
                doc.page_content if hasattr(doc, "page_content") else str(doc)
                for doc in retrieved_docs
            ]
        )

        memory_chunk = ""  # æ­¤ç«¯é»ç„¡è¨˜æ†¶
        is_exercise_mode = request.search_type == "exercise"

        answer = rag_service.generate_answer(
            matched_context,
            request.message,
            request.learner_style,
            memory_chunk,
            subject=current_subject,  # å‚³å…¥ç§‘ç›®
            is_exercise_mode=is_exercise_mode,
            course_title=request.course_title,
            use_alternative=request.use_alternative,
            retry_count=request.retry_count,
        )

        # 5. å¾Œè™•ç† (ç·´ç¿’é¡Œè§£æ/åˆ†æ®µ)
        exercise_question = None
        exercise_answer = None
        segments = []

        if is_exercise_mode:
            import re

            question_match = re.search(
                r"ã€é¡Œç›®ã€‘\s*(.*?)\s*ã€ç­”æ¡ˆã€‘", answer, re.DOTALL
            )
            answer_match = re.search(r"ã€ç­”æ¡ˆã€‘\s*(.*)", answer, re.DOTALL)

            if question_match and answer_match:
                exercise_question = question_match.group(1).strip()
                exercise_answer = answer_match.group(1).strip()
            else:
                exercise_question = answer
                exercise_answer = "ï¼ˆAI æœªæä¾›æ¨™æº–ç­”æ¡ˆæ ¼å¼ï¼‰"
        else:
            from chatbot.rag_pipeline.post_process import Post_process

            post_processor = Post_process()
            segments = post_processor.split_answer(answer)

        # æ•´ç†æ–‡ä»¶è³‡è¨Š
        docs_info = []
        for doc in retrieved_docs[:3]:
            doc_info = {
                "content": doc.page_content
                if hasattr(doc, "page_content")
                else str(doc),
                "metadata": doc.metadata if hasattr(doc, "metadata") else {},
            }
            docs_info.append(doc_info)

        processing_time = time.time() - start_time

        return ChatResponse(
            answer=answer,
            segments=segments,
            retrieved_docs=docs_info,
            processing_time=round(processing_time, 2),
            search_type=request.search_type,
            learner_style=request.learner_style,
            exercise_question=exercise_question,
            exercise_answer=exercise_answer,
            drawing_id=drawing_id,
            drawing_total_steps=total_steps,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è™•ç†è«‹æ±‚éŒ¯èª¤: {str(e)}")


@app.post("/chat_with_history", response_model=ChatResponse)
async def chat_with_history(request: ChatRequest):
    """å¸¶è¨˜æ†¶çš„èŠå¤©ç«¯é»"""
    if not rag_initialized:
        raise HTTPException(status_code=503, detail="RAG æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")

    start_time = time.time()
    try:
        # 1. æ±ºå®šç§‘ç›®
        current_subject = (
            request.subject if request.subject in ["math", "science"] else "math"
        )
        selected_vs = vector_stores[current_subject]

        if not selected_vs["teaching"] or not selected_vs["exercise"]:
            if current_subject == "science" and vector_stores["math"]["teaching"]:
                selected_vs = vector_stores["math"]
                current_subject = "math"
            else:
                raise HTTPException(
                    status_code=400, detail=f"ç§‘ç›® {current_subject} çš„è³‡æ–™åº«æœªè¼‰å…¥"
                )

        teaching_db = (selected_vs["teaching"], [])
        exercise_db = (selected_vs["exercise"], [])

        if request.search_type == "teaching":
            top_n = 3
        elif request.search_type == "exercise":
            top_n = 1
        else:
            top_n = 4

        # 2. æª¢ç´¢
        retrieved = rag_service.retrival_step(
            [request.message],
            request.search_type,
            teaching_db,
            exercise_db,
            top_n=top_n,
            course_filter=request.course_title,
        )
        retrieved_docs = retrieved.get(request.message, [])
        drawing_id, total_steps = get_drawing_info(retrieved_docs)

        # 3. è¨˜æ†¶è™•ç†
        matched_context = "\n".join([doc.page_content for doc in retrieved_docs])
        memory_chunk = ""
        if request.history:
            recent_history = request.history[-10:]
            memory_lines = []
            for msg in recent_history:
                role = "å­¸ç”Ÿå•" if msg.role == "user" else "åŠ©æ•™ç­”"
                memory_lines.append(f"{role}: {msg.content}")
            memory_chunk = "\n".join(memory_lines)

        # 4. ç”Ÿæˆ
        is_exercise_mode = request.search_type == "exercise"
        answer = rag_service.generate_answer(
            matched_context,
            request.message,
            request.learner_style,
            memory_chunk,
            subject=current_subject,  # å‚³å…¥ç§‘ç›®
            is_exercise_mode=is_exercise_mode,
            course_title=request.course_title,
            use_alternative=request.use_alternative,
            retry_count=request.retry_count,
        )

        # 5. å¾Œè™•ç†
        exercise_question = None
        exercise_answer = None
        segments = []
        if is_exercise_mode:
            import re

            question_match = re.search(
                r"ã€é¡Œç›®ã€‘\s*(.*?)\s*ã€ç­”æ¡ˆã€‘", answer, re.DOTALL
            )
            answer_match = re.search(r"ã€ç­”æ¡ˆã€‘\s*(.*)", answer, re.DOTALL)
            if question_match and answer_match:
                exercise_question = question_match.group(1).strip()
                exercise_answer = answer_match.group(1).strip()
            else:
                exercise_question = answer
                exercise_answer = "ï¼ˆAI æœªæä¾›æ¨™æº–ç­”æ¡ˆæ ¼å¼ï¼‰"
        else:
            from chatbot.rag_pipeline.post_process import Post_process

            post_processor = Post_process()
            segments = post_processor.split_answer(answer)

        docs_info = [
            {"content": d.page_content, "metadata": d.metadata}
            for d in retrieved_docs[:3]
        ]
        processing_time = time.time() - start_time

        return ChatResponse(
            answer=answer,
            segments=segments,
            retrieved_docs=docs_info,
            processing_time=round(processing_time, 2),
            search_type=request.search_type,
            learner_style=request.learner_style,
            exercise_question=exercise_question,
            exercise_answer=exercise_answer,
            drawing_id=drawing_id,
            drawing_total_steps=total_steps,
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è™•ç†è«‹æ±‚éŒ¯èª¤: {str(e)}")


@app.post("/clarify", response_model=ClarifyResponse)
async def clarify_segment(request: ClarifyRequest):
    if not rag_initialized:
        raise HTTPException(status_code=503, detail="RAG æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")
    start_time = time.time()
    try:
        original_docs = request.original_context if request.original_context else ""
        clarification = rag_service.generate_clarification(
            request.selected_text,
            request.original_query,
            original_docs,
            request.learner_style,
        )
        processing_time = time.time() - start_time
        return ClarifyResponse(
            clarification=clarification, processing_time=round(processing_time, 2)
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("fastapi_app:app", host="0.0.0.0", port=8001, reload=True)
