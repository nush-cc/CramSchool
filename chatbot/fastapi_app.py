"""
FastAPI æœå‹™ - RAG èŠå¤©æ©Ÿå™¨äºº (å¤šå­¸ç§‘æ”¯æ´ç‰ˆ + å¤–éƒ¨é€£çµæ•´åˆ)
ç”¨æ–¼å­¸ç”Ÿå•ç­”ç³»çµ±çš„å¾Œç«¯ API
"""

import os
import random
import sys
import time
from typing import List, Optional, Dict, Any

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field

# è¨­å®šè·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)

if project_root not in sys.path:
    sys.path.append(project_root)

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
env_path = os.path.join(project_root, ".env")
load_dotenv(env_path)

# å°å…¥ RAG ç›¸é—œæ¨¡çµ„
from chatbot.rag_pipeline.RAG_function import rag_process


# ==================== Helper Functions ====================

def get_drawing_info(retrieved_docs):
    import json

    DRAWING_DIR = os.path.join(
        project_root, "chatbot", "dataset", "llama_drawing_steps"
    )

    for doc in retrieved_docs:
        if hasattr(doc, "metadata"):
            doc_id = doc.metadata.get("id")
            if doc_id:
                target_filename = f"{doc_id}_layout.json"
                full_path = os.path.join(DRAWING_DIR, target_filename)

                if os.path.exists(full_path):
                    try:
                        with open(full_path, "r", encoding="utf-8") as f:
                            data = json.load(f)
                            steps = len(data.get("steps", []))
                            return str(doc_id), steps
                    except Exception as e:
                        print(f"è®€å– Layout JSON å¤±æ•—: {e}")
                        continue
    return None, 0


def get_simulation_info(retrieved_docs):
    """
    å¾æª¢ç´¢åˆ°çš„æ–‡ä»¶ä¸­æå–æ¨¡æ“¬ç¶²ç«™ URL
    æ”¯æ´: Dictionary ç‰©ä»¶ æˆ– JSON String
    """
    import json  # ç¢ºä¿æœ‰å¼•å…¥ json

    for doc in retrieved_docs:
        sim_data = None

        # 1. å–å¾—åŸå§‹è³‡æ–™
        if hasattr(doc, "metadata"):
            sim_data = doc.metadata.get("simulation")
        elif isinstance(doc, dict):
            # é˜²å‘†: å¦‚æœ doc æœ¬èº«å°±æ˜¯ dict (é Document ç‰©ä»¶)
            sim_data = doc.get("metadata", {}).get("simulation")

        if not sim_data:
            continue

        # 2. é—œéµä¿®æ­£: å¦‚æœæ˜¯å­—ä¸²ï¼Œå…ˆè½‰æˆ Dict
        if isinstance(sim_data, str):
            try:
                sim_data = json.loads(sim_data)
            except Exception as e:
                print(f"âš ï¸ Simulation JSON è§£æå¤±æ•—: {e}")
                continue

        # 3. ç¾åœ¨ sim_data è‚¯å®šæ˜¯ Dict äº†ï¼Œæ”¾å¿ƒå–å€¼
        if isinstance(sim_data, dict):
            url = sim_data.get("url")
            if url:
                print(f"ğŸ¯ [get_simulation_info] æˆåŠŸæå– URL: {url}")
                return url

    return None


def get_random_exercise(subject, course_filter=None):
    """
    å¾ç·´ç¿’é¡Œåº«ä¸­éš¨æ©ŸæŠ½å–ä¸€é¡Œ
    """
    # 1. å–å¾—è©²ç§‘ç›®çš„ç·´ç¿’é¡Œ vectorstore
    vs = vector_stores.get(subject, {}).get("exercise")
    if not vs:
        return []

    # 2. å–å¾—æ‰€æœ‰æ–‡ä»¶ (å¾ docstore)
    # FAISS çš„ docstore._dict å­˜æœ‰æ‰€æœ‰ Document ç‰©ä»¶
    all_docs = list(vs.docstore._dict.values())

    candidates = []

    # 3. éæ¿¾å–®å…ƒ (å¦‚æœæœ‰æŒ‡å®š)
    if course_filter:
        print(f"ğŸ² [Random] æ­£åœ¨ç¯©é¸å–®å…ƒ: {course_filter}")
        for doc in all_docs:
            category = doc.metadata.get("category", "")
            # é€™è£¡åšç°¡å–®çš„å­—ä¸²åŒ…å«æ¯”å°
            if course_filter in category:
                candidates.append(doc)
    else:
        # æ²’æŒ‡å®šå–®å…ƒå°±å…¨æ¢­äº†
        candidates = all_docs

    print(f"ğŸ² [Random] å€™é¸é¡Œæ•¸: {len(candidates)}")

    # 4. éš¨æ©ŸæŠ½ä¸€é¡Œ
    if candidates:
        selected = random.choice(candidates)
        return [selected]  # å›å‚³ list æ ¼å¼ä»¥é…åˆåŸæœ¬æµç¨‹

    return []


# ==================== Pydantic Models ====================


class ChatMessage(BaseModel):
    role: str = Field(..., description="user æˆ– assistant")
    content: str = Field(..., description="è¨Šæ¯å…§å®¹")


class ChatRequest(BaseModel):
    """èŠå¤©è«‹æ±‚æ¨¡å‹"""

    message: str = Field(..., description="å­¸ç”Ÿçš„å•é¡Œ", min_length=1)
    subject: str = Field(
        default="math", description="ç§‘ç›®: math (æ•¸å­¸) æˆ– science (è‡ªç„¶)"
    )
    search_type: str = Field(
        default="teaching", description="æª¢ç´¢é¡å‹: teaching, exercise, hybrid"
    )
    learner_style: str = Field(
        default="æ¨™æº–ç´š", description="å­¸ç¿’é¢¨æ ¼: åŸºç¤ç´š, æ¨™æº–ç´š, é€²éšç´š"
    )
    course_id: Optional[int] = Field(default=None, description="èª²ç¨‹ IDï¼ˆå¯é¸ï¼‰")
    course_title: Optional[str] = Field(default=None, description="èª²ç¨‹æ¨™é¡Œ/ä¸»é¡Œ")
    history: Optional[List[ChatMessage]] = Field(default=[], description="å°è©±æ­·å²")
    is_retry: bool = Field(default=False, description="æ˜¯å¦ç‚ºé‡è©¦è«‹æ±‚")
    retry_count: int = Field(default=0, description="é‡è©¦æ¬¡æ•¸")
    use_alternative: bool = Field(default=False, description="æ˜¯å¦ä½¿ç”¨æ›¿ä»£è§£é‡‹")


class ChatResponse(BaseModel):
    answer: str = Field(..., description="AI ç”Ÿæˆçš„ç­”æ¡ˆ")
    segments: List[str] = Field(default=[], description="ç­”æ¡ˆåˆ†æ®µ")
    retrieved_docs: List[Dict[str, Any]] = Field(
        default=[], description="æª¢ç´¢åˆ°çš„ç›¸é—œæ–‡ä»¶"
    )
    processing_time: float = Field(..., description="è™•ç†æ™‚é–“")
    search_type: str = Field(..., description="ä½¿ç”¨çš„æª¢ç´¢é¡å‹")
    learner_style: str = Field(..., description="ä½¿ç”¨çš„å­¸ç¿’é¢¨æ ¼")
    exercise_question: Optional[str] = Field(default=None)
    exercise_answer: Optional[str] = Field(default=None)

    # ç•«åœ–ç›¸é—œ
    drawing_id: Optional[str] = Field(default=None)
    drawing_total_steps: int = Field(default=0)

    # æ–°å¢: å¤–éƒ¨é€£çµç›¸é—œ
    simulation_url: Optional[str] = Field(default=None, description="å¤–éƒ¨æ¨¡æ“¬ç¶²ç«™ URL")


class ClarifyRequest(BaseModel):
    selected_text: str = Field(..., description="å­¸ç”Ÿé¸ä¸­çš„æ–‡å­—ç‰‡æ®µ")
    original_query: str = Field(..., description="åŸå§‹å•é¡Œ")
    learner_style: str = Field(default="æ¨™æº–ç´š")
    original_context: Optional[str] = Field(default=None)


class ClarifyResponse(BaseModel):
    clarification: str = Field(..., description="æ·±å…¥è§£é‡‹")
    processing_time: float = Field(..., description="è™•ç†æ™‚é–“")


class HealthResponse(BaseModel):
    status: str
    rag_loaded: bool
    message: str


# ==================== FastAPI App ====================

app = FastAPI(
    title="RAG èŠå¤©æ©Ÿå™¨äºº API (å¤šå­¸ç§‘)",
    description="æ”¯æ´æ•¸å­¸èˆ‡è‡ªç„¶ç§‘çš„å•ç­”ç³»çµ±",
    version="2.1.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== å…¨åŸŸè®Šæ•¸ ====================

rag_service = None
rag_initialized = False

# ä½¿ç”¨å­—å…¸ä¾†ç®¡ç†ä¸åŒç§‘ç›®çš„ VectorStore
# çµæ§‹: { "math": {"teaching": VS, "exercise": VS}, "science": ... }
vector_stores = {
    "math": {"teaching": None, "exercise": None},
    "science": {"teaching": None, "exercise": None},
}

# è³‡æ–™è·¯å¾‘é…ç½® (éœ€èˆ‡ build_faiss.py å°æ‡‰)
PATH_CONFIG = {
    "math": {
        "teaching": "faiss_index_teaching",
        "exercise": "faiss_index_exercise",
        "ex_json": os.path.join(
            DATASET_DIR := os.path.join(current_dir, "dataset"),
            "raw_data",
            "add_id_data",
            "question_math_id.json",
        ),
    },
    "science": {
        "teaching": "faiss_index_science_teaching",
        "exercise": "faiss_index_science_exercise",
        "ex_json": os.path.join(
            DATASET_DIR, "raw_data", "add_id_data", "question_science_id.json"
        ),
    },
}


# ==================== å•Ÿå‹•äº‹ä»¶ ====================


@app.on_event("startup")
async def startup_event():
    global rag_service, rag_initialized, vector_stores
    print("\n" + "=" * 60)
    print("ğŸš€ FastAPI RAG æœå‹™å•Ÿå‹•ä¸­ (å¤šå­¸ç§‘æ¨¡å¼)...")
    print("=" * 60)

    try:
        # åˆå§‹åŒ– RAG è™•ç†å™¨
        print("\n[1/3] åˆå§‹åŒ– RAG è™•ç†å™¨...")
        rag_service = rag_process()

        # æº–å‚™ Embedding æ¨¡å‹
        from langchain_community.vectorstores import FAISS
        from langchain_community.embeddings import HuggingFaceBgeEmbeddings
        from chatbot.config import embedding_model_name, model_device

        model_kwargs = {"device": model_device}
        embeddings = HuggingFaceBgeEmbeddings(
            model_name=embedding_model_name,
            model_kwargs=model_kwargs,
            encode_kwargs={"normalize_embeddings": True},
        )
        print("   âœ… Embedding æ¨¡å‹è¼‰å…¥å®Œæˆ")

        # è¼‰å…¥æ‰€æœ‰ç§‘ç›®çš„å‘é‡åº«
        print("\n[2/3] è¼‰å…¥å‘é‡è³‡æ–™åº«...")

        for subj, paths in PATH_CONFIG.items():
            t_path = os.path.join(current_dir, paths["teaching"])
            e_path = os.path.join(current_dir, paths["exercise"])

            # è¼‰å…¥æ•™å­¸åº«
            if os.path.exists(t_path):
                print(f"   ğŸ“š [{subj}] è¼‰å…¥æ•™å­¸å‘é‡åº«: {paths['teaching']}")
                vector_stores[subj]["teaching"] = FAISS.load_local(
                    t_path, embeddings, allow_dangerous_deserialization=True
                )
            else:
                print(f"   âš ï¸ [{subj}] æ‰¾ä¸åˆ°æ•™å­¸åº«: {paths['teaching']}")

            # è¼‰å…¥ç·´ç¿’åº«
            if os.path.exists(e_path):
                print(f"   ğŸ“š [{subj}] è¼‰å…¥ç·´ç¿’å‘é‡åº«: {paths['exercise']}")
                vector_stores[subj]["exercise"] = FAISS.load_local(
                    e_path, embeddings, allow_dangerous_deserialization=True
                )
            else:
                print(f"   âš ï¸ [{subj}] æ‰¾ä¸åˆ°ç·´ç¿’åº«: {paths['exercise']}")

        # æª¢æŸ¥ OpenAI API Key
        print("\n[3/3] æª¢æŸ¥ OpenAI API...")
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("æ‰¾ä¸åˆ° OPENAI_API_KEY")

        rag_initialized = True
        print("\nâœ… æœå‹™å•Ÿå‹•æˆåŠŸï¼")

    except Exception as e:
        print(f"\nâŒ å•Ÿå‹•å¤±æ•—: {str(e)}")
        rag_initialized = False
        raise


@app.get("/health", response_model=HealthResponse)
async def health_check():
    return HealthResponse(
        status="ok" if rag_initialized else "error",
        rag_loaded=rag_initialized,
        message="RAG æœå‹™é‹è¡Œæ­£å¸¸" if rag_initialized else "RAG æœå‹™æœªåˆå§‹åŒ–",
    )


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    if not rag_initialized:
        raise HTTPException(status_code=503, detail="RAG æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")

    start_time = time.time()

    try:
        # 1. æ±ºå®šç§‘ç›® (é˜²å‘†)
        current_subject = (
            request.subject if request.subject in ["math", "science"] else "math"
        )

        # 2. å–å‡ºå°æ‡‰çš„ VectorStore
        selected_vs = vector_stores[current_subject]
        if not selected_vs["teaching"] or not selected_vs["exercise"]:
            # å¦‚æœè©²ç§‘ç›®çš„è³‡æ–™åº«æ²’è¼‰å…¥ï¼Œå›é€€åˆ° math æˆ–å ±éŒ¯
            if current_subject == "science" and vector_stores["math"]["teaching"]:
                print("Warning: Science DB not found, fallback to Math")
                selected_vs = vector_stores["math"]
                current_subject = "math"
            else:
                raise HTTPException(
                    status_code=400, detail=f"ç§‘ç›® {current_subject} çš„è³‡æ–™åº«æœªè¼‰å…¥"
                )

        # æ§‹å»º DB Tuple (VS, DS) - é€™è£¡ç°¡åŒ– DS ç‚ºç©ºåˆ—è¡¨
        teaching_db = (selected_vs["teaching"], [])
        exercise_db = (selected_vs["exercise"], [])

        if request.search_type == "teaching":
            top_n = 3
        elif request.search_type == "exercise":
            top_n = 1
        else:
            top_n = 4

        # 3. æª¢ç´¢
        retrieved = rag_service.retrival_step(
            [request.message],
            request.search_type,
            teaching_db,
            exercise_db,
            top_n=top_n,
            course_filter=request.course_title,
        )

        retrieved_docs = retrieved.get(request.message, [])

        # --- æ•´åˆé¡å¤–è³‡æº (ç•«åœ– & å¤–éƒ¨ç¶²ç«™) ---
        drawing_id, total_steps = get_drawing_info(retrieved_docs)
        simulation_url = get_simulation_info(retrieved_docs)  # <--- æ–°å¢æ­¤è¡Œ

        # 4. ç”Ÿæˆç­”æ¡ˆ
        matched_context = "\n".join(
            [
                doc.page_content if hasattr(doc, "page_content") else str(doc)
                for doc in retrieved_docs
            ]
        )

        memory_chunk = ""  # æ­¤ç«¯é»ç„¡è¨˜æ†¶
        is_exercise_mode = request.search_type == "exercise"

        answer = rag_service.generate_answer(
            matched_context,
            request.message,
            request.learner_style,
            memory_chunk,
            subject=current_subject,  # å‚³å…¥ç§‘ç›®
            is_exercise_mode=is_exercise_mode,
            course_title=request.course_title,
            use_alternative=request.use_alternative,
            retry_count=request.retry_count,
        )

        # 5. å¾Œè™•ç† (ç·´ç¿’é¡Œè§£æ/åˆ†æ®µ)
        exercise_question = None
        exercise_answer = None
        segments = []

        if is_exercise_mode:
            import re

            question_match = re.search(
                r"ã€é¡Œç›®ã€‘\s*(.*?)\s*ã€ç­”æ¡ˆã€‘", answer, re.DOTALL
            )
            answer_match = re.search(r"ã€ç­”æ¡ˆã€‘\s*(.*)", answer, re.DOTALL)

            if question_match and answer_match:
                exercise_question = question_match.group(1).strip()
                exercise_answer = answer_match.group(1).strip()
            else:
                exercise_question = answer
                exercise_answer = "ï¼ˆAI æœªæä¾›æ¨™æº–ç­”æ¡ˆæ ¼å¼ï¼‰"
        else:
            from chatbot.rag_pipeline.post_process import Post_process

            post_processor = Post_process()
            segments = post_processor.split_answer(answer)

        # æ•´ç†æ–‡ä»¶è³‡è¨Š
        docs_info = []
        for doc in retrieved_docs[:3]:
            doc_info = {
                "content": doc.page_content
                if hasattr(doc, "page_content")
                else str(doc),
                "metadata": doc.metadata if hasattr(doc, "metadata") else {},
            }
            docs_info.append(doc_info)

        processing_time = time.time() - start_time

        return ChatResponse(
            answer=answer,
            segments=segments,
            retrieved_docs=docs_info,
            processing_time=round(processing_time, 2),
            search_type=request.search_type,
            learner_style=request.learner_style,
            exercise_question=exercise_question,
            exercise_answer=exercise_answer,
            drawing_id=drawing_id,
            drawing_total_steps=total_steps,
            simulation_url=simulation_url,  # <--- æ–°å¢æ­¤è¡Œ
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è™•ç†è«‹æ±‚éŒ¯èª¤: {str(e)}")


@app.post("/chat_with_history", response_model=ChatResponse)
async def chat_with_history(request: ChatRequest):
    """å¸¶è¨˜æ†¶çš„èŠå¤©ç«¯é»"""
    if not rag_initialized:
        raise HTTPException(status_code=503, detail="RAG æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")

    start_time = time.time()
    try:
        # 1. æ±ºå®šç§‘ç›®
        current_subject = (
            request.subject if request.subject in ["math", "science"] else "math"
        )
        selected_vs = vector_stores[current_subject]

        if not selected_vs["teaching"] or not selected_vs["exercise"]:
            if current_subject == "science" and vector_stores["math"]["teaching"]:
                selected_vs = vector_stores["math"]
                current_subject = "math"
            else:
                raise HTTPException(
                    status_code=400, detail=f"ç§‘ç›® {current_subject} çš„è³‡æ–™åº«æœªè¼‰å…¥"
                )

        teaching_db = (selected_vs["teaching"], [])
        exercise_db = (selected_vs["exercise"], [])

        if request.search_type == "teaching":
            top_n = 3
        elif request.search_type == "exercise":
            top_n = 1
        else:
            top_n = 4

        # 2. æª¢ç´¢
        retrieved = rag_service.retrival_step(
            [request.message],
            request.search_type,
            teaching_db,
            exercise_db,
            top_n=top_n,
            course_filter=request.course_title,
        )
        retrieved_docs = retrieved.get(request.message, [])

        # ========== DEBUG å€å¡Š ==========
        # print("\n" + "=" * 40)
        # print(f"ğŸ§ [DEBUG] æ”¶åˆ°å•é¡Œ: {request.message}")
        # print(f"âš™ï¸ [DEBUG] åƒæ•¸è¨­å®š: Subject={current_subject}, SearchType={request.search_type}")
        # print(f"ğŸ·ï¸ [DEBUG] èª²ç¨‹éæ¿¾: {request.course_title} (è‹¥é None å‰‡æœƒé€²è¡Œéæ¿¾)")
        # print(f"ğŸ“Š [DEBUG] æª¢ç´¢çµæœæ•¸é‡: {len(retrieved_docs)} ç­†")
        #
        # if len(retrieved_docs) == 0:
        #     print("âš ï¸ è­¦å‘Šï¼šæª¢ç´¢çµæœç‚ºç©ºï¼è«‹æª¢æŸ¥ Subject æˆ– Course Title æ˜¯å¦è¨­é™éåš´ã€‚")
        # else:
        #     for i, doc in enumerate(retrieved_docs):
        #         meta = doc.metadata if hasattr(doc, "metadata") else {}
        #         sim = meta.get("simulation")
        #
        #         print(f"--- æ–‡ä»¶ {i + 1} ---")
        #         print(f"   ğŸ“‚ Category: {meta.get('category', 'N/A')}")
        #         if sim:
        #             print(f"   âœ… æ‰¾åˆ° Simulation (Type: {type(sim)})")
        #             print(f"   ğŸ‘€å…§å®¹: {sim}")
        #         else:
        #             print(f"   âŒ ç„¡ Simulation")
        #
        # sim_url = get_simulation_info(retrieved_docs)
        # print(f"ğŸš€ [DEBUG] æœ€çµ‚æå–çš„ URL: {sim_url}")
        # print("=" * 40 + "\n")
        # ===============================        # =========================================

        # --- æ•´åˆé¡å¤–è³‡æº (ç•«åœ– & å¤–éƒ¨ç¶²ç«™) ---
        drawing_id, total_steps = get_drawing_info(retrieved_docs)
        simulation_url = get_simulation_info(retrieved_docs)  # <--- æ–°å¢æ­¤è¡Œ

        # 3. è¨˜æ†¶è™•ç†
        matched_context = "\n".join([doc.page_content for doc in retrieved_docs])
        memory_chunk = ""
        if request.history:
            recent_history = request.history[-10:]
            memory_lines = []
            for msg in recent_history:
                role = "å­¸ç”Ÿå•" if msg.role == "user" else "åŠ©æ•™ç­”"
                memory_lines.append(f"{role}: {msg.content}")
            memory_chunk = "\n".join(memory_lines)

        # 4. ç”Ÿæˆ
        is_exercise_mode = request.search_type == "exercise"
        answer = rag_service.generate_answer(
            matched_context,
            request.message,
            request.learner_style,
            memory_chunk,
            subject=current_subject,  # å‚³å…¥ç§‘ç›®
            is_exercise_mode=is_exercise_mode,
            course_title=request.course_title,
            use_alternative=request.use_alternative,
            retry_count=request.retry_count,
        )

        # 5. å¾Œè™•ç†
        exercise_question = None
        exercise_answer = None
        segments = []
        if is_exercise_mode:
            import re

            question_match = re.search(
                r"ã€é¡Œç›®ã€‘\s*(.*?)\s*ã€ç­”æ¡ˆã€‘", answer, re.DOTALL
            )
            answer_match = re.search(r"ã€ç­”æ¡ˆã€‘\s*(.*)", answer, re.DOTALL)
            if question_match and answer_match:
                exercise_question = question_match.group(1).strip()
                exercise_answer = answer_match.group(1).strip()
            else:
                exercise_question = answer
                exercise_answer = "ï¼ˆAI æœªæä¾›æ¨™æº–ç­”æ¡ˆæ ¼å¼ï¼‰"
        else:
            from chatbot.rag_pipeline.post_process import Post_process

            post_processor = Post_process()
            segments = post_processor.split_answer(answer)

        docs_info = [
            {"content": d.page_content, "metadata": d.metadata}
            for d in retrieved_docs[:3]
        ]
        processing_time = time.time() - start_time

        return ChatResponse(
            answer=answer,
            segments=segments,
            retrieved_docs=docs_info,
            processing_time=round(processing_time, 2),
            search_type=request.search_type,
            learner_style=request.learner_style,
            exercise_question=exercise_question,
            exercise_answer=exercise_answer,
            drawing_id=drawing_id,
            drawing_total_steps=total_steps,
            simulation_url=simulation_url,  # <--- æ–°å¢æ­¤è¡Œ
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è™•ç†è«‹æ±‚éŒ¯èª¤: {str(e)}")


@app.post("/clarify", response_model=ClarifyResponse)
async def clarify_segment(request: ClarifyRequest):
    if not rag_initialized:
        raise HTTPException(status_code=503, detail="RAG æœå‹™å°šæœªåˆå§‹åŒ–å®Œæˆ")
    start_time = time.time()
    try:
        original_docs = request.original_context if request.original_context else ""
        clarification = rag_service.generate_clarification(
            request.selected_text,
            request.original_query,
            original_docs,
            request.learner_style,
        )
        processing_time = time.time() - start_time
        return ClarifyResponse(
            clarification=clarification, processing_time=round(processing_time, 2)
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("fastapi_app:app", host="0.0.0.0", port=8001, reload=True)
